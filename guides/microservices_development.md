## Microservices development

> Перед прочтением этого гайда обязательно ознакомьтесь с [гайдом по Kubernetes](./guide_kubernetes.md).

В данном гайде разобраны основные нюансы и проблемы, возникающие при разработке микросервисных приложений.

Цифрами отмечена сложность и важность темы:
- 1 - Простая тема. Достаточно того, что написано в этом гайде.
- 2 - Важная тема. Могут попросить объяснить на собеседовании. Но слишком глубоко углубляться не надо.
- 3 - Очень важная тама. С большой долей вероятности спросят на собеседовании. Следует хорошо разобраться.

### Паттерны микросервисной архитектуры

Работая с микросервисной архитектурой, команды сталкиваются с похожими проблемами. Для их решения выделили паттерны микросервисной архитектуры. В данной секции мы ознакомимся с основными из них.

<b>(2) Pattern: Distributed tracing / распределенная трасировка запроса</b> - запрос пользователя проходит через несколько микросервисов, и нам бы хотелось видеть полный путь запроса пользователя для его дальнейшего анализа. Например, запрос выполняется слишком долго, и мы хотим узнать, на каком из микросервисов он зависает. Одним из наиболее популярных инструментов для реализации этого паттерна является [Jaeger](https://habr.com/ru/company/srg/blog/446752/).

<b>(2) Pattern: Log aggregation / распределенный сбор логов</b> - когда у нас много приложений, каждое из них засписывает свои логи в файл на сервере, где приложение развернуто. Было бы крайне неудобно заходить на каждый сервер и вручную скачивать файл с логами, а в случае с Kubernetes иногда это было бы вообще невозможно, так как поды постоянно создаются и удаляются, и вместе с приложением удаляется и порожденный им лог. Надо собирать эти логи, передавать их в центральное хранилище и анализировать с помощью какого-нибудь инструмента. Для решение этих задач сущетсвуют целые стеки технологий, один из самых известных - [EFK](https://habr.com/ru/company/otus/blog/721004/). И еще одна [статья](https://habr.com/ru/company/southbridge/blog/510822/).

<b>(2) Pattern: Application metrics / мониторинг</b> - нам бы хотелось знать, что происходит с нашим приложением во время его работы: количество запросов, пришедших за определенное время, загруженность хипа, количество используемых потоков, частота сборок мусора, время выполнения запроса. Самый популярный инструмент для этого - [Prometheus](https://habr.com/ru/post/709204/) и Grafana для визуализации метрик. [Статья](https://habr.com/ru/post/548700/) про передачу метрик из Spring-приложения

<b>(1) Pattern: Health Check API</b> - если приложение сейчас по каким-то причинам не готово принимать запросы (только запускается, перегружено или вообще умерло), то остальной системе стоит об этом знать для предотвращения возможных ошибок при обращении к этому приложению. Реализовать этот паттерн с помощью Spring и Kubernetes достаточно просто. У Kubernetes существуют так называемые Readiness и Liveness probes. Первая служит для проверки готовности свежесозданной Pod'ы принимать трафик (пример, когда нам это может понадобиться - это только что запущенное Spring приложение, у которого еще не прогрузился контекст). Вторая нужна для периодической проверки работоспособности ранее поднятой поды. В Deployment микросервиса мы указываем, по какому эндпоинту приложения эти Probe'ы должны делать проверку. Сами урлы автоматически настраиваются библиотекой Spring Boot Actuator и имеют вид "/actuator/health/liveness" и "/actuator/health/readiness"

<b>(1) Pattern: API Gateway	/ Single entry point</b> - тут все просто. Большому кластеру микросервисов желательно иметь единую точку входа, после которой запрос уже попадет на нужный микросервис. Можно сказать, что в Kubernetes реализацией этого паттерна является Ingress. Альтернатива Ingress - это Spring Cloud Gateway.

<b>(2) Pattern: Access token</b> - если у нас есть единая точка входа систему, на которой происходит аутентификация и авторизация, то как другие микросервисы узнают, что пришедший запрос точно является авторизованным, и его можно выполнить. Тут может помочь JWT, исчерпывающая информация о котором представлена [тут](./guide_postman_and_security.md).

<b>(1) Pattern: Database per service</b> - у каждого микросервиса должна быть своя база данных. Сами БД при этом обычном разворачиваются не в Кубере, а на отдельных серверах

<b>(3) Pattern: Saga</b> - пример: пришел запрос от пользователя, который успешно обработался на двух микросервисах и они внесли соответствующие изменения в свои БД, но на третьем микросервисе по какой-то причине происходит ошибка, и он не может успешно обработать запрос. Предыдущим двум микросервисам нужно как-то учесть, что запрос не был выполнен, ведь один из этих микросервисов мог вычесть деньги с баланса пользователя за оплату какого-либо товара, который в итоге не был куплен, и теперь эти деньги надо вернуть. Тут может помочь паттерн Saga. Микросервис, который не смог выполнить запрос, должен уведомить остальные микросервисы об этом, которые в свою очередь выполнят необходимые операции для того, чтобы компенсировать неудачный запрос. Уведомить он может любым способом, например, по REST-эндпоинтам всех зависимых микросервисов, но это неудобно, поэтому используют брокер сообщений, например, Kafka, о котором я расскажу позже. Есть альтернативы этому паттерну, например, 2PC, но самым оптимальным считается Saga, у которого в свою очередь есть два подвида, мы разобрали Choreography-based saga, достаточно хорошо изучить только его. [Статья](https://microservices.io/patterns/data/saga.html) про Saga

<b>Опционально. Другие паттерны:</b>
<ol>
<li><a href="https://mcs.mail.ru/blog/26-osnovnyh-patternov-mikroservisnoj-razrabotki">Сайт</a> на русском
<li><a href="https://microservices.io/patterns/index.html">Сайт</a> автора книги "Микросервисы. Паттерны разработки и рефакторинга"
</ol>

<b>Важно! [Теорема CAP](https://en.wikipedia.org/wiki/CAP_theorem)</b> - любая распределенная система подвержена проблемам с соединением (network partitioning), поэтому следует решить, что система должна делать в таких случаях: либо мгновенно возвращать ошибки, тем самым поддержать согласованность/Consistency данных (транзакция в банке), либо продолжить выполнение, ожидая, что рано или поздно данные станут согласованными, когда все элементы системы снова заработают, тем самым поддержав доступность/Availability системы (новостная лента в соц.сети).

### Прочие технологии 

#### Альтернативы REST:

- <b>(1) GraphQL</b> - когда мы запрашиваем данные с помощью REST, мы получаем все поля сущности, что иногда может быть избыточно. Например, у сущности может быть больше сотни полей, а нам нужно только три. Эту проблему помогает решить GraphQL. В запросе GraphQL можно указать, какие именно данные мы хотим получить. Этот фреймворк часто используется как альтернатива REST для общения с фронтом
- <b>(2) gRPC</b> - активно используется для общения микросервисов между собой. Основное преимущество в использовании протокола HTTP 2.0 (REST использует HTTP 1.1), из-за особенностей которого скорость общения клиента и сервера может быстрее в несколько раз. Важно отметить, что этот фреймворк не используется для общения с фронтом, так как браузеры не поддерживают gRPC
- <b>(3) Kafka</b> - брокер сообщений. Способ общения принципиально отличается от указанных выше вариантов. Между клиентом (Producer в терминологии Kafka) и сервером (Consumer) есть приложение-посредник (сама Kafka), куда клиент кладет свое сообщение (запрос), далее Kafka передает это сообщение Consumer'у. Зачем это нужно? Когда мы обращаемся к серверу по REST'у, мы ждем, что сервер нам ответит практически мгновенно (синхронный подход), но может быть так, что именно в этот момент сервер не был готов принять запрос, например, он просто не работает, и тогда наш запрос выполнится с ошибкой. Брокер сообщений же позволяет нам положить наш запрос (сообщение) в очередь сообщений, а сервер получит это сообщение тогда, когда будет готов его прочитать (асинхронный подход). Аналогия из жизни: синхронный подход - это когда мы лично подходим к человеку и задаем ему вопрос, асинхронный подход - это когда мы ему отправляем сообщение по почте. На всякий случай добавлю, что брокеры сообщений не испольщуются для общения с фронтом. Отличное [видео](https://www.youtube.com/watch?v=-AZOi3kP9Js) про основы Kafka.

#### Spring Cloud
Несмотря на то, что Kubernetes позволяет отказаться от некоторых ключевых модулей Spring Cloud, он не исключает все. Spring Cloud - это набор модулей, каждый из которых по-своему облегчает разработку микросервисов, например:
- <b>(1) Feign client</b> - более удобная и умная альтернатива RestTemplate. Позволяет делать запросы к REST-API, конфигурировать ретраи (Retry - повторные вызовы сервера, если при первом вызове получили ошибку), настроить логирование запроса, настроить таймаут (сколько ждать ответ от сервера) и прочее
- <b>(1) Sleuth</b> - трасировка запроса (в секции про паттерны я писал про трасировку). Клиентская библиотека, добавляемая в Spring приложение, которая обогащает запросы заголовками, нужными для трасировки запросов. Альтернатива клиентской библиотеке Jaeger, которая упоминалась в статье в секции про Паттерны
- <b>(2) Spring Cloud's Circuit Breaker</b> - реализация паттерна Circuit Breaker. В микросервисной архитектуре мы никогда не можем быть уверены, что вызываемый микросервис будет доступен, поэтому надо предусмотреть поведение в случае недоступности вызываемого сервера. Spring Cloud's Circuit Breaker позволяет настроить лимит количества ошибок при обращении к какому-то ресурсу и задать поведение в случае достижения установленного лимита

#### (2) CI/CD - Jenkins

Результат разработки нашего приложения - это .jar-файл, и впоследствии - Docker-образ. Кто-то должен их собрать и выложить в общедоступное хранилище, чтобы потом их можно было использовать для деплоя приложения.

Если компания и команда совсем небольшая, то как сборкой приложения, так его дальнейшим деплоем можно заниматься вручную. Но когда команда разрастается, то это становится очень неудобно и отнимает лишнее время, поэтому практически все сколько-нибудь прибыльные проекты используют CI/CD - системы, самой популярной из которых является Jenkins.

Jenkins по своей сути - это приложение, которое разворачивается на сервере, и его основной задачей является сборка и деплой проектов. Приложения, написанные на java, он может собирать так же, как их собираем мы у себя локально, c помощью Maven'а. Деплой в Kubernetes он может делать так же, как его делаем мы на проекте, с помощью kubectl. Инструмент является очень гибким, и через него можно настроить автоматизацию чего угодно.

Небольшой [курс](https://www.youtube.com/playlist?list=PLg5SS_4L6LYvQbMrSuOjTL1HOiDhUE_5a) про Jenkins. Достаточно посмотреть до третьей части включительно. 

С большой долей вероятности вам никогда не придется настраивать Jenkins с нуля, но вам точно нужно понимать, что это такое, а учиться пользоваться им вы будете на работе.

### FAQ по организации работы

<ul>
<li>Методология разработки - Scrum/Agile
<li>Как эстемировать задачи - Planning poker/Scrum poker
<li>Стратегия ветвления - GitFlow
<li>Оптимальный состав Agile-команды - 1 владелец продукта (Product Owner), 2 тестировщика (QA), 2 аналитика (системных или бизнес), 2-4 бекенд-разработчика, один из которых - тимлид. Если есть фронт, то добавляется 1 фронт-разработчик и, возможно, 1 UI/UX-дизайнер. DevOps обычно не является частью команды, но приходит на помощь команде в случае необходимости, простые DevOps-задачи выполняют бекенд-разработчики
<li>Сколько команд могут работать над одним проектом - достаточно много. В зависимости от размера компании и проекта, может быть более 10-и команд, каждая из которых может отвечать за свою часть функционала и разрабатывать свои микросервисы
<li>Что такое тестовый стенд - это среда, в которой развернуто приложение, имитирующая продакшн. Оптимальное количество - 3: DEV стенд для разработчиков, ИФТ стенд для тестировщиков, ПСИ стенд для финального тестирования перед передачей в Продакшн
<li>Как правятся баги, обнаруженные уже после установки нового релиза в продакшн - в приоритете правится баг и делается hotfix релиза
<li>Как разработчики документируют код - OpenAPI (Swagger)					
<li>Где аналитики пишут документацию - Confluence						
<li>Самый популярный таск-менеджер - Jira
<li>Самый популярный хостинг репозиториев в крупных компаниях - BitBucket (однако некоторые компании используют GitLab, например, Ozon)
<li>Самый популярный хостинг репозиториев в небольших и средних компаниях - GitLab
<li>Как автоматизировать контроль качества кода и процент покрытия кода тестами - настроить SonarQube, который будет сканировать код в основных ветках в репозитории
<li>Популярное хранилище артефактов (.jar-ников и Docker-образов, которые потом используются Kubernetes) - Sonatype Nexus
</ul>